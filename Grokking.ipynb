{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f535a1",
   "metadata": {},
   "source": [
    "## Исследование эффекта гроккинга "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1cb90a",
   "metadata": {},
   "source": [
    "За основу взята статья Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets:  \n",
    "https://arxiv.org/pdf/2201.02177.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7250561",
   "metadata": {},
   "source": [
    "Выполнили: Грозный Сергей, Мельник Юрий 209 гр."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8374357",
   "metadata": {},
   "source": [
    "## 1. Вступление"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f47e2a",
   "metadata": {},
   "source": [
    "В данной статье описывается т.н. эффект гроккинга: нейросеть резко переходит от качества случайного угадывания к идеальному качеству, причём случается это сильно после точки переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb143d5b",
   "metadata": {},
   "source": [
    "Авторы данной работы наблюдают этот эффект на данных вида aob=c, где \"a\",\"b\",\"c\" - числа, а \"o\" - некая операция. Состовляется таблица, где строки и столбцы это всевозможные значения \"a\" и \"b\", в ячейках которой хранятся соответствующие этим \"a\" и \"b\" - \"c\". Далее, случайным образом стираются некоторые ячейки(то есть разбиваем выборку на train и test(пустые ячейки)). Задача состоит в том, чтобы заполнить пустые ячейки в соответствии с выше описанной операцией."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fc93a",
   "metadata": {},
   "source": [
    "В этой научной работе авторы наблюдали этот эффект на многих операциях, но мы остановимся на нескольких из них. Тип нейросети - трансформер, в качестве оптимизатора будем использовать AdamW, поскольку данный эффект наиболее отчетливо наблюдается при его использовании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62ee74",
   "metadata": {},
   "source": [
    "## 2. Программная реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c35f29",
   "metadata": {},
   "source": [
    "### Библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8357a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from net import Grokformer  # net - файл с реализацией трансформера\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083af83",
   "metadata": {},
   "source": [
    "### Функция генерации данных:  \n",
    "p - деление по модулю p  \n",
    "function - операция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3977773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_p(p: int, function):\n",
    "    x = torch.arange(p)  # 0..p\n",
    "    y = torch.arange(1, p)  # 1..p\n",
    "    x, y = torch.cartesian_prod(x, y).T  # декартово произведение x и y\n",
    "    result = function(x, y) % p\n",
    "    return torch.stack([x, y, result]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba42bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(a, b):  # a*b\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e2b700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinm(a, b):  # целая часть модуля синуса от a+b\n",
    "    return (abs(torch.sin(a+b))*sinp).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3f087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesim(a, b):  # несимметричная функция a*b+b*b\n",
    "    return (a*b+b*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e2ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 97\n",
    "device = torch.device(\"cuda:0\")  # \"cpu\" - процессор, \"cuda:0\" - видеокарта\n",
    "train_ratio = 0.4  # какая доля выборки уйдет на train\n",
    "batch_size = 512\n",
    "budget = 10000  # регулирует кол-во эпох\n",
    "sinp = 3*p  # множитель для функции синуса, чтобы результат был от 0 до sinp\n",
    "func = prod  # операция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095cc9d",
   "metadata": {},
   "source": [
    "Авторы статьи в качестве входных параметров для трансформера использовали токены \"a\",\"o\",\"b\",\"=\",\"c\", но мы будем использовать только \"a\", \"b\", \"c\". Как нам кажется, токены \"o\" и \"=\" никакой ценности для нейросети не несут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9476edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  0],\n",
      "        [ 0,  2,  0],\n",
      "        [ 0,  3,  0],\n",
      "        ...,\n",
      "        [96, 94,  3],\n",
      "        [96, 95,  2],\n",
      "        [96, 96,  1]])\n"
     ]
    }
   ],
   "source": [
    "# 1, 2, 3 столбец - \"a\", \"b\", \"c\" соответственно\n",
    "example = create_data_p(p, func)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0bd49",
   "metadata": {},
   "source": [
    "Перемешиваем выборку и разбиваем на train и val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d842e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_p(p, func)\n",
    "data = data.to(device)\n",
    "data_index = torch.randperm(data.shape[0], device=device)\n",
    "split = int(data.shape[0] * train_ratio)\n",
    "training_set = data[data_index[:split]]\n",
    "validation_set = data[data_index[split:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa745ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[90, 15, 89],\n",
       "        [46, 29, 73],\n",
       "        [21, 55, 88],\n",
       "        ...,\n",
       "        [32, 34, 21],\n",
       "        [22, 67, 19],\n",
       "        [19, 82,  6]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc13700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[53, 45, 57],\n",
       "        [84, 66, 15],\n",
       "        [90, 55,  3],\n",
       "        ...,\n",
       "        [46, 49, 23],\n",
       "        [57, 23, 50],\n",
       "        [92, 78, 95]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используется модель из файла net.py\n",
    "net = Grokformer(num_embeddings=99, embedding_dim=128, device=device)\n",
    "optimizer = AdamW(net.parameters(), lr=1e-3, weight_decay=1., betas=(0.9, 0.98))\n",
    "scheduler = LambdaLR(optimizer, lambda epoch: min(epoch/10, 1.))  # регулятор learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e4e4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# кол-во шагов оптимизации за 1 эпоху\n",
    "steps_per_epoch = math.ceil(training_set.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7287ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, val_acc, train_loss, val_loss = [], [], [], []\n",
    "s = np.array([])  # сумма норм весов на каждой эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad8de570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1250/1250 [01:54<00:00, 10.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(int(budget) // steps_per_epoch)):\n",
    "\n",
    "    # на каждой эпохе перемешиваем train\n",
    "    training_set = training_set[torch.randperm(training_set.shape[0]), :]\n",
    "\n",
    "    for data, is_train in [(training_set, True), (validation_set, False)]:\n",
    "\n",
    "        total_acc = 0\n",
    "        total_loss = 0\n",
    "        net.train(is_train)\n",
    "\n",
    "        dl = torch.split(data, batch_size, dim=0)  # делим на батчи\n",
    "        for input in dl:  # input - 1 батч\n",
    "            input = input.to(device)  # используем видеокарту\n",
    "            with torch.set_grad_enabled(is_train):\n",
    "                logits = net(input[:, :-1])  # предсказание\n",
    "                loss = cross_entropy(\n",
    "                    logits, input[:, -1].flatten().to(torch.long))\n",
    "                total_loss += loss.item() * input.shape[0]\n",
    "\n",
    "            if is_train:  # пересчитываем веса, вычисляя градиенты; обновляем lr\n",
    "                net.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            acc = (logits.argmax(-1) == input[:, -1]).float().mean()\n",
    "            total_acc += acc.item()*input.shape[0]\n",
    "\n",
    "        if is_train:\n",
    "            # Считаем сумму норм весов модели\n",
    "            # *************************************************************************\n",
    "            f = 0\n",
    "            for name, parameter in net.named_parameters():\n",
    "                if (\"weight\" in name) and (\"norm\" not in name) and (\"emb\" not in name):\n",
    "                    f += torch.norm(parameter, p=2).item()\n",
    "            s = np.append(s, f)\n",
    "            # *************************************************************************\n",
    "\n",
    "            train_acc.append(total_acc / training_set.shape[0])\n",
    "            train_loss.append(total_loss / training_set.shape[0])\n",
    "        else:\n",
    "            val_acc.append(total_acc / validation_set.shape[0])\n",
    "            val_loss.append(total_loss / validation_set.shape[0])\n",
    "    if (epoch + 1) % 100 == 0:  # каждые 100 эпох обновляем графики точности и ошибки\n",
    "        steps = torch.arange(len(train_acc)).numpy() * steps_per_epoch\n",
    "        plt.plot(steps, train_acc, label=\"train\")\n",
    "        plt.plot(steps, val_acc, label=\"val\")\n",
    "        plt.legend()\n",
    "        plt.title(\"x*y mod 97 (training on 40% of data)\")\n",
    "        plt.xlabel(\"Optimization Steps\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xscale(\"log\", base=10)\n",
    "        # графики сохраняются в папке figures\n",
    "        plt.savefig(\"figures/acc.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(steps, train_loss, label=\"train\")\n",
    "        plt.plot(steps, val_loss, label=\"val\")\n",
    "        plt.legend()\n",
    "        plt.title(\"x*y mod 97 (training on 40% of data)\")\n",
    "        plt.xlabel(\"Optimization Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xscale(\"log\", base=10)\n",
    "        plt.savefig(\"figures/loss.png\", dpi=150)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf780919",
   "metadata": {},
   "source": [
    "Построение графика суммы норм весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ac879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x*steps_per_epoch for x in range(len(s))], s)\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.title(\"x*y mod 97 (training on 40% of data)\")\n",
    "plt.xlabel(\"Optimization Steps\")\n",
    "plt.ylabel(\"Weights\")\n",
    "plt.savefig(\"figures/nweights.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be99a5",
   "metadata": {},
   "source": [
    "## 3. Подтверждение результатов, полученных авторами статьи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ff61e",
   "metadata": {},
   "source": [
    "В первую очередь мы решили проверить результаты, полученные авторами статьи, а именно:\n",
    "<ol>\n",
    "<li>Эффект действительно наблюдается на данных из статьи.</li>\n",
    "<li>На симметричных функциях данный эффект чаще наблюдается, чем на несимметричных.  </li>\n",
    "<li>С увеличением доли обучающей выборки увеличивается скорость наблюдения эффекта.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01492f74",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/40%/loss.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f3537",
   "metadata": {},
   "source": [
    "Как и было заявлено, на симметричной функции эффект наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5705d6",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy+yy/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy+yy/40%/loss.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d0002",
   "metadata": {},
   "source": [
    "А на несимметричной функции добиться нужного эффекта не удалось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a60876",
   "metadata": {},
   "source": [
    "Теперь будем увеличивать долю обучающей выборки для симметричной операции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec7265",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/60%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/70%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy/80%/acc.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/90%/acc.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119350e",
   "metadata": {},
   "source": [
    "Действительно, с ростом доли обучающей выборки модель быстрее выходит на хорошую обобщающую способность после переобучения. Также стоит отметить случай, когда обучающая выборка составляет 80% от всей выборки, здесь как и на результатах, полученных авторами, наблюдается неожиданное ухудшение точности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98496b1a",
   "metadata": {},
   "source": [
    "<img src=\"Graphics/train_ratio.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd7226",
   "metadata": {},
   "source": [
    "Отметим, что для операций \"x/y\" и \"xy\" по модулю простого числа результат совпадает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f4e0a",
   "metadata": {},
   "source": [
    "Проверим данное наблюдение на несимметричной функции:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069c5d7",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy+yy/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy+yy/80%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55482f7",
   "metadata": {},
   "source": [
    "Несмотря на то, что при увеличении доли обучающей выборки имеются предпосылки для наблюдения эффекта гроккинга (правый рисунок), достигнуть желаемой точности не удается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3de41f",
   "metadata": {},
   "source": [
    "## 4. Анализ эффекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d08c67",
   "metadata": {},
   "source": [
    "### Другая операция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fff4ae",
   "metadata": {},
   "source": [
    "Рассмотрим операцию, которая не использовалась в статье. Попробуем на какую-нибудь симметричную операцию навесить относительно сложную функцию, например синус. Для того, чтобы работать с целыми неотрицательными числами,  берем целую часть от модуля синуса, причем, чтобы деление по модулю на 97 имело смысл, умножим результат на некоторую константу \"sinp\", большую 97. Значение константы регулируется в программе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35dc8a",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/sin(x+y)/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/sin(x+y)/40%/loss.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1aac98",
   "metadata": {},
   "source": [
    "Даже на такой, казалось бы, сложной функции эффект наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6493e7",
   "metadata": {},
   "source": [
    "Попробуем увеличить долю обучающей выборки:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697df02d",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/sin(x+y)/50%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/sin(x+y)/70%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/sin(x+y)/80%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e841dc",
   "metadata": {},
   "source": [
    "Заметим, что на 50% эффект гроккинга наблюдается не так отчетливо, причем у модели начинают появляться трудности даже на обучающей выборке. При дальнейшем увеличении нашего параметра эффект становится все менее различимым и не достигается необходимая точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7aa53e",
   "metadata": {},
   "source": [
    "### Анализ весов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f12950",
   "metadata": {},
   "source": [
    "Проанализируем значения суммы норм весов модели на разных шагах оптимизации:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590c7a9",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy/40%/nweights.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/40%/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8ea68",
   "metadata": {},
   "source": [
    "Отметим, что рост значения весов соответствует началу увеличения точности на обучающей выборке(отрезок от 0.75\\*10^3 до 10^3 шагов оптимизации). Далее при достижении точности на train, равной 1, и дальнейшем переобучении просходит немонотонный рост весов (отрезок от 10^3 до 0.5\\*10^4) вплоть до точки максимума, которой соответствует началу роста точности на валидационной выборке. После происходит резкое уменьшение значений весов, которое сопровождается увеличением точности на val вплоть до 1 (луч от 0.5\\*10^4 и далее)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d375",
   "metadata": {},
   "source": [
    "Другими словами происходит следующее: веса сначала улетают в большие значения, переобучаясь, а потом спускаются вниз вдоль своего рода \"направляющего вектора\", который выдает одинаковые ответы, но имеет более низкий модуль весов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99283571",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3105dc",
   "metadata": {},
   "source": [
    "Попробуем убрать weight decay, заменив AdamW на Adam. Сравним графики изменения весов для этих оптимизаторов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcb838",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Graphics/xy/Adam/acc.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"Graphics/xy/Adam/nweights.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c5d60",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что для Adam значения весов модели на протяжении всего времени увеличиваются из-за отсутсвии L2 регуляризации, которая \"штрафует\" за большие значения весов. То есть не будет точки, начиная с которой значения весов будут уменьшатся, что соответствует началу гроккинга(по нашему предположению). Из этого можно сделать вывод, что weight decay играет ключевую роль в этом эффекте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be42bd",
   "metadata": {},
   "source": [
    "## 5. Гипотезы и предположения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396082af",
   "metadata": {},
   "source": [
    "Основываясь на результатах, описанных в статье и своих собственных, мы можем сделать следующие предположения:\n",
    "1. С ростом доли обучающей выборки модель склоняется в пользу \"выучивания\" операции, а не пытается \"запомнить\" все данные, как происходит при переобучении.   \n",
    "2. Немаловажную роль играет L2-регуляризация, которая добавляет \"гладкости\" предсказанию. Это можно наблюдать на рисунке ниже: левый график соответствует переобучению модели, что ведет к потери точности на тестовой выборке; правый - переобучение также присутствует, но засчет l2 регуляризации график проходит \"гладко\" через все точки и складывается впечатление, что модель выучила правило.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b604f7",
   "metadata": {},
   "source": [
    "<img src=\"Graphics/weight_decay.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d387c6",
   "metadata": {},
   "source": [
    "3. В некоторый момент после наступления переобучения засчет наличия weight decay, штраф за веса начинает превалировать над ошибкой модели, что заставляет ее искать другое решение с точки зрения выгоды относительно весов, которое в конечном счете оказывается оптимальным.\n",
    "4. Прослеживается схожесть с раннее открытым явлением \"double descent\" и поэтому, вероятно, они имеют одинаковую природу возникновения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c874bd1",
   "metadata": {},
   "source": [
    "## Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369bfbad",
   "metadata": {},
   "source": [
    "В ходе проделанной работы мы познакомились с основами глубинного обучения, разобрались в устройстве нейросети трансформер, изучили библиотеку pytorch, что позволило нам воспроизвести эффект гроккинга и сделать предположения относительно причин его возникновения. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
